from __future__ import (print_function,
                        division)
from keras.callbacks import Callback
from keras import backend as K
import theano
import numpy as np


class Dice(Callback):
    """
    Compute the dice over the full set of data.
    
    Expects the following metrics: d_I, d_A, d_B
    d_I : number of pixels in the intersection of masks A and B
    d_A : number of pixels in mask A
    d_B : number of pixels in mask B
    
    Also requires a dummy 'dice' metric to record this callback's output.
    The functions for these metrics can be retrieved via get_metrics() and
    must be passed to the keras model's metrics list on model compilation.
    
    target_class : the integer class (or list of classes) for which to compute
        the Dice score. All classes in a list are treated as one aggregate 
        class.
    mask_class : the class (or list of classes) to mask out from the ground
        truth input.
    tag : the tag to append to all metric names. If it is not specified, one
        is autogenerated as an underscore-separated list of target_class
        classes followed an underscore-separated list of mask_class classes,
        each prepended with "m" (eg: dice_2_m0 for target_class=2, 
        mask_class=0).
    output_name : to specify if there is more than one output in the model in
        which case, the output name should be prepended to the metric names.
    """
    
    def __init__(self, target_class, mask_class=None, tag=None,
                 output_name=None):
        self.target_class = target_class
        if not hasattr(target_class, '__len__'):
            self.target_class = [target_class]
        auto_tag = "_"+"_".join(str(i) for i in self.target_class)
        self.mask_class = mask_class
        if mask_class is not None and not hasattr(mask_class, '__len__'):
            self.mask_class = [mask_class]
        if mask_class is not None:
            auto_tag += "_"+"_".join("m"+str(i) for i in self.mask_class)
        self.tag = tag or auto_tag
        self.output_name = output_name
        self.__name__ = 'dice'+self.tag        
                     
    def _name(self, core_name):
        name = core_name+self.tag
        if self.output_name is not None:
            name = self.output_name+"_"+name
        return name
    
    def get_metrics(self):
        '''
        Get keras metrics that compute the values consumed by this callback 
        (d_I, d_A, dB) and a dummy metric that serves only to create an 
        'dice' keyword entry for storing the computed dice value.
        
        All intermediate metrics are divided by the number of samples to
        counterbalance the way keras collects metrics across batches (by
        averaging across all samples).
        '''    
        def full_dice_metrics(y_true, y_pred):
            y_true_f = K.flatten(y_true)
            y_true_f = K.cast(y_true_f, 'int32')
            y_pred_f = K.flatten(y_pred)
            y_target = K.sum([K.equal(y_true_f, t) for t in self.target_class],
                             axis=0)
            if self.mask_class is not None:
                mask_out = K.sum([K.equal(y_true_f, t) \
                                             for t in self.mask_class], axis=0)
                idxs = K.not_equal(mask_out, 1).nonzero()
                y_target = y_target[idxs]
                y_pred_f = y_pred_f[idxs]
            y_target = K.greater_equal(y_target, 0.5)
            n = y_true.shape[0]
            return {'d_I'+self.tag: K.sum(y_target * y_pred_f)/n,
                    'd_A'+self.tag: K.sum(y_target)/n,
                    'd_B'+self.tag: K.sum(y_pred_f)/n,
                    'dice'+self.tag: theano.tensor.as_tensor_variable(0)}
        
        def keras_wrapper(key):
            # A function wrapper for keras' broken API
            def wrapper(y_true, y_pred):
                out = full_dice_metrics(y_true, y_pred)
                return out[key]
            # Ugly hack to name a metric, required by keras' API
            wrapper.__name__ = key
            return wrapper
        
        metrics = []
        for key in ['d_I', 'd_A', 'd_B', 'dice']:
            metrics.append(keras_wrapper(key+self.tag))
        return metrics
    
    def on_epoch_begin(self, epoch, logs=None):
        self.totals = {self._name('d_I'): 0,
                       self._name('d_A'): 0,
                       self._name('d_B'): 0}
        
    def on_batch_end(self, batch, logs=None):
        logs = logs or {}
        
        # Record d_I, d_A, d_B
        for k in self.totals.keys():
            if k not in logs:
                raise ValueError("Dice callback expects metrics "
                                "{}, {}, {} but {} is missing."
                                "".format(self._name('d_I'),
                                          self._name('d_A'),
                                          self._name('d_B'), k))
            if k not in self.totals:
                self.totals[k] = 0
            self.totals[k] += logs[k]
            
        # Compute dice
        dice = 1.
        if self.totals[self._name('d_A')] or self.totals[self._name('d_B')]:
            dice = self.compute_dice(I=self.totals[self._name('d_I')],
                                     A=self.totals[self._name('d_A')],
                                     B=self.totals[self._name('d_B')])
        
        # Update the dictionary (write the dice metric and remove used metrics)
        logs[self._name('dice')] = dice
        for k in self.totals.keys():
            logs.pop(k)
        self.dice = {self._name('dice'): dice}
        
        
    def on_epoch_end(self, epoch, logs=None):
        # Update logs; if validation values exist, compute validation dice.
        logs = logs or {}
        val_totals = {}
        logs.update(self.dice)
        for k in self.totals.keys():
            logs.pop(k)
            if 'val_'+k in logs:
                val_totals[k] = logs.pop('val_'+k)
        if len(val_totals):
            val_dice = self.compute_dice(I=val_totals[self._name('d_I')],
                                         A=val_totals[self._name('d_A')],
                                         B=val_totals[self._name('d_B')])
            logs['val_'+self._name('dice')] = val_dice
            
    def compute_dice(self, I, A, B):
        if not (A or B):
            return 1.
        else:
            return 2*I/float(A+B)


class FileLogger(Callback):
    '''Callback that prints loss and metrics to file.
    '''
    def __init__(self, log_file_path, log_write_mode='at'):
        self.log_file_path = log_file_path
        self.log_write_mode = log_write_mode

    def __del__(self):
        if hasattr(self, 'log_file') and self.log_file is not None:
            self.log_file.close()

    def write_log(self, log_values):
        if self.log_file is not None:
            msg = "Epoch {} - batch {} :: ".format(self.epoch, self.batch)
            for i, key in enumerate(sorted(self.log_values.keys())):
                if i>0:
                    msg += " - "
                msg += str(key)+": "+str(self.log_values[key])
            print(msg, file=self.log_file)
            self.log_file.flush()

    def on_train_begin(self, logs={}):
        self.epochs = self.params['epochs']
        self.epoch = 0
        if self.log_file_path is not None:
            try:
                self.log_file = open(self.log_file_path, self.log_write_mode)
            except:
                print("Failed to open file in FileLogger: "
                      "{}".format(self.log_file_path))
                raise

    def on_epoch_begin(self, epoch, logs={}):
        self.epoch = epoch

    def on_batch_begin(self, batch, logs={}):
        self.batch = batch
        self.log_values = {}

    def on_batch_end(self, batch, logs={}):
        batch_size = logs.get('size', 0)
        for k in self.params['metrics']:
            if k in logs:
                self.log_values[k] = logs[k]
        self.write_log(self.log_values)

    def on_epoch_end(self, epoch, logs={}):
        pass
